{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chicken-commons",
   "metadata": {},
   "source": [
    "# EXPLORATION_SSAC2\n",
    "\n",
    "## 2. Iris의 세 가지 품종, 분류해볼 수 있겠어요?\n",
    "\n",
    "학습 목표\n",
    "\n",
    "- scikit-learn에 내장된 예제 데이터셋의 종류를 알고 활용할 수 있다.\n",
    "- scikit-learn에 내장된 분류 모델들을 학습시키고 예측해 볼 수 있다.\n",
    "- 모델의 성능을 평가하는 지표의 종류에 대해 이해하고, 활용 및 확인해 볼 수 있다.\n",
    "- Decision Tree, XGBoost, RandomForest, 로지스틱 회귀 모델을 활용해서 간단하게 학습 및 예측해 볼 수 있다.\n",
    "- 데이터셋을 사용해서 스스로 분류 기초 실습을 진행할 수 있다.\n",
    "\n",
    "\n",
    "학습 전제\n",
    "\n",
    "- scikit-learn을 활용해서 머신러닝을 시도해본 적이 없다.\n",
    "- scikit-learn에 내장된 분류 모델을 활용해본 적이 없다.\n",
    "- 지도학습의 분류 실습을 해 본 적이 없다.\n",
    "- 머신러닝 모델을 학습시켜보고, 그 성능을 평가해본 적이 없다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(dir(iris))\n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys() # iris 에 어떤 정보가 담겼는지 keys() 메서드로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = iris.data # 가장 중요한 데이터는 iris_data 변수에 저장 후 크기 확인\n",
    "\n",
    "print(iris_data.shape) #shape는 배열의 형상정보를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data[0] # 샘플 데이터 확인 : sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-reporter",
   "metadata": {},
   "source": [
    "### 목표\n",
    "꽃잎과 꽃받침의 길이가 주어지는 경우 그 꽃은 세 가지의 붓꽃 품종 중 어떤 것인지 맞추기\n",
    "\n",
    "### 해야할 것\n",
    "머신러닝 모델에게 꽃잎, 꽃받침의 길이와 폭 정보를 입력했을 때, 붓꽃의 품종을 출력하도록 학습을 시켜야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-summer",
   "metadata": {},
   "source": [
    "> 머신러닝 모델이 출력해야하는 정답을 **라벨(Label)** or **타겟(target)** 이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_label = iris.target # 붓꽃에서 타겟 정보는 이렇게 볼 수 있음\n",
    "print(iris_label.shape)\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-indonesia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names # 4개의 각 feature에 대한 설명이 담겨있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.filename # 데이터셋 파일이 저장된 경로 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-specialist",
   "metadata": {},
   "source": [
    "## 1번째 머신러닝 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df[\"label\"] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-bailey",
   "metadata": {},
   "source": [
    "### 데이터셋과 테스트 셋을 분리하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-division",
   "metadata": {},
   "source": [
    "## 2-5. 첫 번째 머신러닝 실습, 간단하고도 빠르게! (2) 첫 번째 머신러닝 모델 학습시키기\n",
    "\n",
    "머신러닝은 크게 지도학습 (Supervised Learning), 비지도 학습 (Unsupervised Learning)이라는 두 가지로 구분됩니다.\n",
    "간단히 말해서 지도학습은 지도받을 수 있는, 즉 정답이 있는 문제에 대해 학습하는 것을 말하고, 반대로 비지도 학습은 정답이 없는 문제를 학습하는 것을 말합니다.\n",
    "\n",
    "저희가 지금 해결하고자 하는 붓꽃 품종 문제는 어디에 해당할까요? 데이터에는 정답이 있었나요, 없었나요?\n",
    "\n",
    "\n",
    "네, 저희에게는 label이라는 정답지가 있었죠. 모델이 지도받을 수 있다는 이야기입니다. 즉, 붓꽃 품종 문제는 지도학습에 해당합니다.\n",
    "\n",
    "지도학습은 다시 두 가지로 나눌 수 있는데, 바로 분류(Classification)와 회귀(Regression)입니다.\n",
    "분류는 입력받은 데이터를 특정 카테고리 중 하나로 분류해내는 문제를, 회귀는 입력받은 데이터에 따라 특정 필드의 수치를 맞히는 문제를 말합니다.\n",
    "\n",
    "다시 한번 또 고민해 보죠. 붓꽃 품종 문제는 분류 문제인가요, 회귀 문제인가요?\n",
    "\n",
    "네, 저희에게는 label이라는 정답지가 있었죠. 모델이 지도받을 수 있다는 이야기입니다. 즉, 붓꽃 품종 문제는 지도학습에 해당합니다.\n",
    "\n",
    "지도학습은 다시 두 가지로 나눌 수 있는데, 바로 분류(Classification)와 회귀(Regression)입니다.\n",
    "분류는 입력받은 데이터를 특정 카테고리 중 하나로 분류해내는 문제를, 회귀는 입력받은 데이터에 따라 특정 필드의 수치를 맞히는 문제를 말합니다.\n",
    "\n",
    "다시 한번 또 고민해 보죠. 붓꽃 품종 문제는 분류 문제인가요, 회귀 문제인가요?\n",
    "\n",
    "\n",
    "자, 그러면 정리해봅시다.\n",
    "\n",
    "우리가 해결하고자 하는 붓꽃 문제는\n",
    "\n",
    "- 첫 번째, 머신러닝 중 정답이 있고 그 정답을 맞히기 위해 학습하는 지도 학습(Supervised Learning)이며,\n",
    "- 지도학습 중에서는 특정 카테고리 중 주어진 데이터가 어떤 카테고리에 해당하는지를 맞히는 분류(Classification)문제\n",
    "라고 할 수 있겠습니다.\n",
    "\n",
    "그러면 여기까지 정리가 되었으니 우리는 무슨 머신러닝 모델을 써야할지 명확해집니다. 지도학습 중에서도 분류를 할 수 있는 모델을 사용하면 되죠.\n",
    "\n",
    "분류 모델은 아주 다양하지만, 그 중 저희는 첫 번째로 Decision Tree 모델을 사용해 보도록 하겠습니다.\n",
    "Decision Tree는 직관적이면서도 간단하게 사용할 수 있어 분류 문제를 풀 때 가장 기본적으로 쓰이는 모델 중 하나입니다.\n",
    "\n",
    "Decision Tree의 알고리즘을 설명하는 다음 글을 한번 읽어보죠. 비교적 수학적인 내용이 많아서 쉽지 않을 수 있지만, 이해가 잘 안 가더라도 편하게 읽어보세요.\n",
    "\n",
    "네, 간단히 말해 Decision Tree는 의사 결정을 할, 즉 데이터를 분리할 어떤 경계를 찾아내어 데이터를 체에 거르듯 한 단계씩 분류해나가는 모델입니다.\n",
    "\n",
    "Decision Tree는 sklearn.tree 패키지 안에 DecisionTreeClassifier 라는 이름으로 내장되어 있습니다.\n",
    "모델을 import해서 가져오고, decision_tree 라는 변수에 모델을 저장해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-parish",
   "metadata": {},
   "source": [
    "자, 그러면 모델은 어떻게 학습시킬까요?\n",
    "\n",
    "놀라지 마세요. 지금까지 길게 거쳐온 과정이 무색하게, 모델 학습은 아주 간단하답니다.\n",
    "물론 이 간단함은 scikit-learn이 모델 학습을 편리하게 할 수 있도록 설계한 API 구조 덕이기도 합니다.\n",
    "\n",
    "모델 학습은 우리가 준비해 둔 X_train 와 y_train 데이터로, 다음 한 줄이면 완료됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-endorsement",
   "metadata": {},
   "source": [
    "여기서 눈여겨 볼 점은 학습하는 메서드의 이름이 fit이라는 점입니다.\n",
    "training dataset 으로 모델을 학습시킨다는 것은, 달리 말하면 training dataset에 맞게 모델을 fitting, 즉 맞추는 것이라고 할 수 있습니다.\n",
    "training dataset에 있는 데이터들을 통해 어떠한 패턴을 파악하고, 그 패턴에 맞게 예측을 할 수 있도록 학습되기 때문입니다.\n",
    "\n",
    "즉, 다른 말로 하면 모델은 training dataset에 존재하지 않는 데이터에 대해서는 정확한 정답 카테고리가 무엇인지 알지 못합니다.\n",
    "다만 training dataset을 통해 학습한 패턴으로 새로운 데이터가 어떤 카테고리에 속할지 예측할 뿐이죠.\n",
    "\n",
    "그렇기 때문에 새로운 데이터에 대해서도 잘 맞출 수 있기 위해서는 training dataset이 어떻게 구성되어 있는지가 매우 중요합니다.\n",
    "더 다양한, 더 일반화 된 데이터로 학습이 될수록 새로운 데이터에 대해서도 잘 맞출 수 있는 것이죠.\n",
    "\n",
    "자, 그러면 학습이 완료되었으니 test 데이터로 예측해 보겠습니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-charleston",
   "metadata": {},
   "source": [
    "X_test 데이터에는 정답인 label이 없고 feature 데이터만 존재했습니다. 따라서 학습이 완료된 decision_tree 모델에 X_test 데이터로 predict를 실행하면 모델이 예측한 y_pred을 얻게 됩니다.\n",
    "\n",
    "모델은 총 30개의 데이터에 대해 [2, 1, ...] 라는 예측 결과를 내놓았군요. 실제 정답인 y_test와 비교해서 얼마나 맞았는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-entity",
   "metadata": {},
   "source": [
    "눈으로 간단히 비교해 봤을 때는 어느정도 잘 맞은 것 같지 않나요?\n",
    "\n",
    "예측한 결과에 대한 수치를 조금 더 편리하게 확인할 수 있는 방법이 있습니다. scikit-learn에서 성능 평가에 대한 함수들이 모여있는 sklearn.metrics 패키지를 이용하면 되죠.\n",
    "\n",
    "성능을 평가하는 방법에도 다양한 척도가 있는데, 그 중 정확도(Accuracy)를 간단히 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-brazilian",
   "metadata": {},
   "source": [
    "약 0.9이라는 수치가 나왔군요. 이는 90% 정도의 정확도를 보인다는 뜻입니다.\n",
    "\n",
    "정확도는 전체 개수 중 맞은 것의 개수의 수치를 나타냅니다. 다음과 같은 식으로 나타낼 수 있죠.\n",
    "\n",
    "정확도 = 예측 결과가 정답인 데이터의 개수 / 예측한 전체 데이터의 개수\n",
    "\n",
    "우리의 모델은 30개의 데이터에 대해 예측을 했으니, 그 중 맞은 것은 30 * 0.9 = 27 개라는 것을 역추적해 볼 수 있습니다. 즉 30개 중 27개는 옳은 카테고리로, 3개는 틀린 카테고리로 분류를 했나봅니다.\n",
    "\n",
    "90%의 정확도로 붓꽃의 품종을 잘 판단한다니, 아주 빠르게 학습시켜본 것에 비하면 꽤나 좋은 결과인 것 같지 않나요?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-budapest",
   "metadata": {},
   "source": [
    "## 2-7. 첫번째 머신러닝 실습, 간단하고도 빠르게! (4) 다른 모델도 해 보고 싶다면? 코드 한 줄만 바꾸면 돼!\n",
    "\n",
    "첫 번째 모델을 학습도 시켜보고, 성능도 평가해봤으니 이제는 다른 모델들도 활용해 보겠습니다!\n",
    "\n",
    "다른 모델들을 사용하는 것 또한, 편리하게 설계된 scikit-learn 덕분에 아주 간단합니다. scikit-learn을 사용하는 것에 익숙해진다면 심지어 한 줄의 코드만 수정해도 된다고요!\n",
    "\n",
    "다른 모델들을 다루기 전에 위에서 사용했던 Decision Tree 모델을 학습시키고 예측하는 과정을 한 번에 담아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (2) 데이터 준비\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-sailing",
   "metadata": {},
   "source": [
    "어떤가요? 위에서 여러 가지를 배우면서 진행해서 굉장히 길게 늘어졌던 과정이 사실은 이렇게나 짧고 간단합니다.\n",
    "\n",
    "여기서 모델을 바꿔보고 싶다면 (4) 모델 학습 및 예측 부분에서 모델만 바꿔주면 되죠. 모델이 바뀐다고 해도 위와 같이 진행되는 큰 흐름은 변하지 않으니 이 흐름을 잘 기억해두도록 합시다!\n",
    "\n",
    "**Random Forest**\n",
    "이 외에 간단히 활용해 볼 수 있는 모델들을 만나보겠습니다. 먼저, Decision Tree를 여러 개 모아놓은 **Random Forest**입니다.\n",
    "\n",
    "이전 스텝에서 Random Forest는 Decision Tree 모델을 여러 개 합쳐놓음으로써 Decision Tree의 단점을 극복한 모델이라고 소개했죠. 이러한 기법을 **앙상블(Ensemble)** 기법이라고 합니다. 단일 모델을 여러 개 사용하는 방법을 취함으로써 모델 한 개만 사용할 때의 단점을 집단지성으로 극복하는 개념이죠.\n",
    "\n",
    "\n",
    "군중은 똑똑하다 — Random Forest(https://medium.com/@deepvalidation/title-3b0e263605de)\n",
    "\n",
    "Q10. Random Forest의 Random은 무엇이 랜덤이라는 것을 나타내나요?\n",
    "Random Forest는 여러 개의 의사 결정 트리를 모아 놓은것으로, 각각의 의사 결정 트리를 만들기 위해 쓰이는 특성들을 랜덤으로 선택한다.\n",
    "\n",
    "Random Forest는 상위 모델들이 예측하는 편향된 결과보다, 다양한 모델들의 결과를 반영함으로써 더 다양한 데이터에 대한 의사결정을 내릴 수 있게 합니다.\n",
    "\n",
    "이러한 이유로 Random Forest는 sklearn.ensemble 패키지 내에 들어있습니다. 다음과 같이 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-earth",
   "metadata": {},
   "source": [
    "어떤가요? 역시 매우 간단하게 모델을 학습시키고 사용할 수 있습니다.\n",
    "\n",
    "**다른 scikit-learn 내장 분류모델**\n",
    "\n",
    "이 외에 scikit-learn에 내장된 기본 분류 모델들을 몇 가지 더 사용해 보겠습니다. 오늘은 각 모델에 대한 깊은 이론적인 내용보다는, 사용해 볼 수 있는 것에 초점을 맞추어 연습해 볼 것입니다. 각 모델에 대한 내용들을 이해하기 위한 좋은 글들을 하나씩 첨부하니, 꼭 한 번씩 읽고 넘어가기를 권합니다.\n",
    "\n",
    "코드 사용은 아시다시피 어렵지 않습니다. 전체 틀은 모두 같으니, 직접 코드를 짜보세요!\n",
    "\n",
    "**Support Vector Machine (SVM)**\n",
    "다음 글을 읽고 Support Vector Machine에 대해 알아봅시다.\n",
    "\n",
    "SVM 모델은 다음과 같이 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-affairs",
   "metadata": {},
   "source": [
    "### SVM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-photograph",
   "metadata": {},
   "source": [
    "### SGD 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-index",
   "metadata": {},
   "source": [
    "SGD Classifier 모델은 다음과 같이 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-combination",
   "metadata": {},
   "source": [
    "**Q12. SGD Classifier 모델을 학습시키고, 결과를 확인해 보세요. 아래 코드 셀에서 실행한 후, 정답을 확인하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-ideal",
   "metadata": {},
   "source": [
    "### Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-folks",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "다음 글을 읽고 Logistic Regression 모델에 대해 알아봅시다.\n",
    "\n",
    "Logistic Regression 모델은 다음과 같이 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-delivery",
   "metadata": {},
   "source": [
    "**Q13. Logistic Regression 모델을 학습시고, 결과를 확인해 보세요. 아래 코드 셀에서 실행한 후, 정답을 확인하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-athens",
   "metadata": {},
   "source": [
    "여기까지 첫 번째 머신러닝 실습으로 다양한 모델 학습을 진행해 보았습니다. 어떤가요? 생각보다 간단하지 않나요?\n",
    "\n",
    "사실 우리는 실습을 빠르게 해본다는 목적하에 간단한 설명들로 진행했지만, 그 이면에는 다양한 수학적, 통계적 배경들이 숨어있습니다. 오늘 다루는 내용들 만으로는 그 방대한 것들을 한 번에 다 다룰 수가 없죠.\n",
    "\n",
    "하지만 걱정하지 마세요! 앞으로의 과정들을 통해 하나씩 깊게 다 배워볼 것이니까요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-attraction",
   "metadata": {},
   "source": [
    "## 2-8. 내 모델은 얼마나 똑똑한가? 다양하게 평가해 보기 (1) 정확도에는 함정이 있다\n",
    "\n",
    "앞에서 머신러닝 모델을 빠르게 학습시켜보고, 그 결과도 간단히 확인해 보았습니다.\n",
    "\n",
    "하지만 사실 머신러닝에서는 모델을 학습시키는 것뿐만 아니라 그 성능을 정확히 평가하고 개선하는 것이 매우 중요합니다. 이전 노드에서 정확도라는 척도를 통해 모델의 성능을 확인했던 것, 기억하시나요?\n",
    "\n",
    "모델의 성능을 평가하는 데에는 정확도뿐만 아니라 다른 척도들이 존재합니다. 이번 스텝에서는 다른 척도들을 배워보고, 그 척도들을 간단한 방법으로 확인해 보도록 하겠습니다.\n",
    "\n",
    "**정확도에는 함정이 있다**\n",
    "\n",
    "위에서 우리는 정확도로 모델의 성능을 평가해 보았습니다. 하지만 정확도에는 치명적인 함정이 있죠.\n",
    "\n",
    "어떤 함정이 있는지, 손글씨 데이터인 MNIST 데이터셋으로 확인해 보겠습니다. 붓꽃 데이터를 사용했을 때처럼, 손글씨 데이터도 아래와 같은 코드로 간단히 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-thriller",
   "metadata": {},
   "source": [
    "digits 라는 변수에 손글씨 데이터를 저장했고, 그 안에는 iris 데이터와 똑같이 몇 가지의 정보들이 있군요.\n",
    "\n",
    "가장 중요한 data를 먼저 확인해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-provider",
   "metadata": {},
   "source": [
    "데이터는 총 1,797개가 있고, 각 데이터는 64개의 숫자로 이루어져 있군요. 1,797개의 데이터 중 첫 번째 데이터를 샘플로 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-possession",
   "metadata": {},
   "source": [
    "예상대로 64개의 숫자로 이루어진 배열(array)이 출력되었습니다. 각 숫자는 어떤 의미가 있을까요?\n",
    "\n",
    "손글씨 데이터는 이미지 데이터입니다. 따라서 각 숫자는 픽셀값을 의미하죠. 길이 64의 숫자 배열은 사실 (8 x 8) 크기의 이미지를 일렬로 쭉 펴놓은 것입니다.\n",
    "이미지는 어떻게 생겼는지 한 번 확인해 보겠습니다. 이미지를 보기 위해서는 matplotlib이라는 라이브러리가 필요합니다.\n",
    "\n",
    "matplotlib.pyplot을 plt라는 이름으로 가져오고, 이미지를 현재 화면에 보여주기 위해 %matplotlib inline이라는 코드를 추가하겠습니다.\n",
    "\n",
    "이미지는 다음과 같이 간단히 확인할 수 있습니다. 다만, 일렬로 펴진 64개 데이터를 (8, 8)로 reshape해주는 것을 잊으면 안 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-newton",
   "metadata": {},
   "source": [
    "0처럼 생긴 이미지가 보이는군요.\n",
    "\n",
    "여러 개의 이미지를 한 번에 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-current",
   "metadata": {},
   "source": [
    "네, 해상도가 낮은 이미지이기 때문에 흐릿하지만, 마음의 눈으로 보면 0부터 9까지의 숫자를 볼 수 있습니다.\n",
    "\n",
    "그렇다면 target 데이터는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-medicine",
   "metadata": {},
   "source": [
    "총 1,797개의 데이터가 있고, 0부터 9까지의 숫자로 나타나는군요. 바로 각 이미지 데이터가 어떤 숫자를 나타내는지를 담고 있는 데이터입니다.\n",
    "\n",
    "그러면 우리는 어떤 문제를 풀어야 할까요?\n",
    "\n",
    "붓꽃 문제와 같이, 각 이미지 데이터가 입력되었을 때 그 이미지가 숫자 몇을 나타내는 이미지인지를 맞추는 분류 모델을 학습시키면 됩니다.\n",
    "\n",
    "다만 이번에는 **정확도의 함정**을 확인하는 실험이기 때문에 약간의 장치를 넣어볼 것입니다.\n",
    "\n",
    "숫자 10개를 모두 분류하는 것이 아니라, 해당 이미지 데이터가 **3인지 아닌지**를 맞히는 문제로 변형해서 풀어보는 것입니다. 즉 입력된 데이터가 3이라면 3을, 3이 아닌 다른 숫자라면 0을 출력하도록 하는 모델을 생각해 보겠습니다.\n",
    "\n",
    "그러려면 target인 digits_label을 아래와 같이 살짝 변형할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = [3 if i == 3 else 0 for i in digits_label]\n",
    "new_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-cheat",
   "metadata": {},
   "source": [
    "네, 기존의 label인 digits_label에서 숫자가 3이라면 그대로 3을, 아니라면 0을 가지는 new_label을 만드는 거죠.\n",
    "\n",
    "이제 이 문제를 풀기 위해 다시 Decision Tree를 학습시켜보겠습니다. 모델 학습은 아주 간단했던 것, 기억하시죠? 직접 코드를 짜보세요!\n",
    "\n",
    "**Q14. digits_data와 new_label로 Decision Tree 모델을 학습시키고, 정확도를 확인해 보세요. 아래 코드 셀에서 실행한 후, 정답을 확인하세요.**\n",
    "\n",
    "**(힌트! train_test_split으로 학습 데이터와 테스트 데이터를 만든 후, 모델을 fit 시키고, predict를 통해 예측 결과를 만든 후 accuracy_score를 이용해 정확도를 측정하는 순서로 진행하세요.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    new_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=15)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-prophet",
   "metadata": {},
   "source": [
    "약 93.9%라는 높은 성능이 나왔군요! 👏🏼👏🏼👏🏼\n",
    "\n",
    "바로 이곳에 함정이 있습니다. 어떤 함정일까요? 우리가 풀려고 했던 문제를 생각해봅시다. 총 10개의 숫자 중 3에만 집중을 해서, 3이라면 3으로, 3이 아니라면 0으로 맞추는 문제로 변형했었죠.\n",
    "\n",
    "그런 이유로, 정답 데이터인 label은 0이 매우 많고 3은 적은 불균형 데이터가 되었습니다. 9개의 숫자들은 label이 모두 0이 되었고, 3만 3으로 남아있었으니 대략 90%의 label이 모두 0이라는 이야기가 되죠.\n",
    "\n",
    "이것은 무엇을 의미할까요? 잠시 생각해봅시다. 🤔\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "네, 바로 모델이 전혀 학습하지 않고 **정답을 모두 0으로만 선택해도 정확도가 90%가량이 나오게 된다는 것**입니다. 실제로 확인해 보죠.\n",
    "\n",
    "길이는 y_pred와 같으면서 0으로만 이루어진 리스트를 fake_pred라는 변수로 저장해 보고, 이 리스트와 실제 정답인 y_test간의 정확도를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pred = [0] * len(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, fake_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-wonder",
   "metadata": {},
   "source": [
    "어떤가요? 우리는 어떠한 모델을 사용하지 않고 답을 0으로만 찍었을 뿐인데, 정확도가 92.5%가 나옵니다.\n",
    "\n",
    "이러한 문제는 **불균형한 데이터, unbalanced 데이터**에서 자주 발생할 수 있습니다.\n",
    "\n",
    "즉 정확도는 정답의 분포에 따라 모델의 성능을 잘 평가하지 못하는 척도가 될 수 있는 것이죠.\n",
    "\n",
    "그렇기 때문에 분류 문제에서는 정확도 외에 다양한 평가 척도를 사용합니다. 무엇이 있는지 이제부터 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-visiting",
   "metadata": {},
   "source": [
    "## 2-9. 내 모델은 얼마나 똑똑한가? 다양하게 평가해 보기 (2) 정답과 오답에도 종류가 있다!\n",
    "\n",
    "위에서 확인한 정확도는 전체 데이터 중 맞은 데이터 만 신경 쓰는 척도입니다. 하지만 양성 데이터를 얼마나 많이 맞았느냐도 중요하겠지만, 음성 데이터를 얼마나 안 틀렸느냐도 중요한 경우가 있습니다. 이는 문제에 따라 달라지죠.\n",
    "\n",
    "예를 들어 코로나바이러스에 감염되었는지 얼마나 많은 의심되는 환자를 진단하는 경우, 실제 음성인데 양성으로 오진을 하면 그나마 환자에게는 다행인 일입니다. 하지만 실제 양성인데 음성이라고 오진을 하는 경우는 환자에게 치명적인 상황이 될 것입니다.\n",
    "\n",
    "이렇듯 같은 오진이라도 양성을 잡아내는 데에 실패하는 오진과, 음성을 잡아내는 데에 실패하는 오진은 그 중요도가 다를 수 있습니다.\n",
    "\n",
    "이렇게 정답과 오답을 구분하여 표현하는 방법을 오차 행렬(confusion matrix) 이라고 합니다.\n",
    "\n",
    "오차 행렬은 다음과 같이 sklearn.metrics 패키지 내의 confusion_matrix로 확인할 수 있습니다.\n",
    "\n",
    "모델이 예측했던 손글씨 결과에 관해 확인해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-operation",
   "metadata": {},
   "source": [
    "위에서 이미지로 봤던 오차 행렬과 같이 각각은 왼쪽 위부터 순서대로 \n",
    "T\n",
    "P\n",
    "TP,\n",
    "F\n",
    "N\n",
    "FN, \n",
    "F\n",
    "P\n",
    "FP, \n",
    "T\n",
    "N\n",
    "TN의 개수를 나타냅니다. 특히, 손글씨 문제에서의 0은 Positive 역할을, 3은 Negative 역할을 합니다.\n",
    "\n",
    "T\n",
    "P\n",
    "TP와 \n",
    "T\n",
    "N\n",
    "TN의 값이 320, 18로 비교적 크고 \n",
    "F\n",
    "N\n",
    "FN과 \n",
    "F\n",
    "P\n",
    "FP의 값은 13, 9로 작네요.\n",
    "\n",
    "그러면 모든 숫자를 0으로 예측한 fake_pred의 경우는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, fake_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-hebrew",
   "metadata": {},
   "source": [
    "네, 우리는 모든 데이터를 0, 즉 Positive로 예측했고 Negative로 예측한 것은 없기 때문에 \n",
    "F\n",
    "N\n",
    "FN과 \n",
    "T\n",
    "N\n",
    "TN은 둘 다 0입니다.\n",
    "\n",
    "모델이 예측했던 손글씨 결과의 Precision, Recall, F1 score는 각각 얼마가 되는지 확인해 보죠. sklearn.metrics의 classification_report를 활용하면 각 지표를 한 번에 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-customer",
   "metadata": {},
   "source": [
    "여러 가지 점수가 출력되었습니다.\n",
    "\n",
    "0은 개수가 333개로 많기 때문에 precision과 recall에서 모두 0.97, 0.96으로 어렵지 않게 높은 점수를 받았습니다. 반면 3은 27개뿐이기 때문에 모두 맞추기가 어려웠나 봅니다. precision과 recall은 각각 0.58, 0.67이 나왔군요.\n",
    "\n",
    "그렇다면 fake_pred는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, fake_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-biodiversity",
   "metadata": {},
   "source": [
    "이게 무슨 일이죠? 0에 대한 precision과 recall은 0.93, 1로 매우 높지만 3에 대한 precision과 recall은 둘 다 0입니다. 이건 큰 문제입니다. 0은 잘 잡아내지만, 3은 단 하나도 맞추지 못했다는 뜻이니까요.\n",
    "\n",
    "다시 한번 정확도를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred), accuracy_score(y_test, fake_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-tourist",
   "metadata": {},
   "source": [
    "y_pred와 fake_pred 모두 0.94, 0.925로 큰 차이가 없지만 이제는 알 수 있습니다. 모델의 성능은 정확도만으로 평가하면 안 된다는 것을요!\n",
    "\n",
    "특히, **label이 불균형하게 분포되어있는 데이터**를 다룰 때는 더 조심해야 합니다.\n",
    "\n",
    "Precision과 Recall이 각각 언제 중요해지는지를 이해하고, 앞으로는 상황에 맞는 성능지표로 모델을 평가하시길 바랍니다!\n",
    "\n",
    "여기까지 분류 실습에 필요한 모든 이론적인 내용들을 배워보고, 직접 실습도 해 보았습니다.\n",
    "\n",
    "모든 준비는 끝났어요! 이제 여러분들의 차례입니다. 지금까지 배운 내용들을 활용해봐야겠죠!\n",
    "이제 직접 데이터를 불러오고, 모델도 선택해서 학습시키고 평가해 보세요. 어렵지 않을 거예요! 화이팅 💪🏼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-processor",
   "metadata": {},
   "source": [
    "## 2-10. 데이터가 달라도 문제 없어요!\n",
    "\n",
    "이제 전부 배워봤으니, 혼자서도 진행할 수 있습니다. 새로운 데이터셋을 찾아 위에서 했던 과정 그대로 진행해 보겠습니다. 시작해 보시죠!\n",
    "\n",
    "실습으로는 여러 데이터셋을 다양하게 진행해 보겠습니다. 데이터가 다르더라도 전체 흐름은 같기 때문에 쉽게 따라 해 볼 수 있을 것입니다. 아직 문자열이 들어간 복잡한 데이터를 다루는 방법은 배우지 않았으니, scikit-learn의 예제 데이터를 활용하기로 하죠.\n",
    "\n",
    "데이터셋 소개 : 사이킷런 toy datasets(https://scikit-learn.org/stable/datasets/toy_dataset.html)\n",
    "\n",
    "위에 제공되는 Toy Dataset 중 분류 문제에 적합한 데이터셋은 다음과 같습니다.\n",
    "\n",
    "load_digits : 손글씨 이미지 데이터 (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)\n",
    "load_wine : 와인 데이터 (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)\n",
    "load_breast_cancer : 유방암 데이터 (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "우리가 위에서 했듯, 하나씩 데이터를 자세히 살펴보세요. 어떤 데이터인지 아는 것은 모델 학습의 가장 기본입니다.\n",
    "\n",
    "데이터를 모두 확인하셨나요? 그러면 이제 천천히, 하나씩 진행해 보세요!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-memorial",
   "metadata": {},
   "source": [
    "## 2-11. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-module",
   "metadata": {},
   "source": [
    "첫 번째 실습입니다.\n",
    "\n",
    "아까 잠깐 다뤄보았던 손글씨 이미지를 제대로 0~9까지 열 가지 카테고리로 분류해 보는 실습을 해 보겠습니다.\n",
    "\n",
    "다음 스텝을 참고해 jupyter notebook에 코드를 작성하여 제출해 주세요.\n",
    "\n",
    "**(1) 필요한 모듈 import하기**\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "**(2) 데이터 준비**\n",
    "\n",
    "load_digits 메서드를 사용합니다.\n",
    "\n",
    "**(3) 데이터 이해하기**\n",
    "\n",
    "지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
    "\n",
    "Feature Data 지정하기\n",
    "Label Data 지정하기\n",
    "Target Names 출력해 보기\n",
    "데이터 Describe 해 보기\n",
    "\n",
    "**(4) train, test 데이터 분리**\n",
    "\n",
    "모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
    "X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n",
    "\n",
    "**(5) 다양한 모델로 학습시켜보기**\n",
    "\n",
    "학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
    "\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기\n",
    "\n",
    "**(6) 모델을 평가해 보기**\n",
    "\n",
    "학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-agreement",
   "metadata": {},
   "source": [
    "### 1. Decision Tree 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chronic-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# (2) 데이터 준비\n",
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-alberta",
   "metadata": {},
   "source": [
    "### 2. Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "randomforest_tree = RandomForestClassifier(random_state=32)\n",
    "randomforest_tree.fit(X_train, y_train)\n",
    "y_pred = randomforest_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-milan",
   "metadata": {},
   "source": [
    "### 3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-profile",
   "metadata": {},
   "source": [
    "### 4. SGD Classifier 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-mainstream",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fundamental-symbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(random_state=32, max_iter = 5000, solver='lbfgs') # max_iter : 정수, 기본값 =100\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-writer",
   "metadata": {},
   "source": [
    "### 문제점\n",
    "\n",
    "LogisticRegression(random_state=32, max_iter = 5000, solver='lbfgs')\n",
    "\n",
    "max_iter : 정수\n",
    "\n",
    "기본값이 100으로 할당되어 있어 용량문제로 오류 메세지가 뜸\n",
    "\n",
    "그래서 5000으로 올리고 실행하니까 문제 없음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-attendance",
   "metadata": {},
   "source": [
    "## 2-12. 프로젝트 (2) load_wine : 와인을 분류해 봅시다\n",
    "\n",
    "이번에는 와인 데이터입니다. 와인의 어떤 특징으로 와인의 종류를 분류해 볼 수 있을까요?\n",
    "\n",
    "데이터에 어떤 정보가 담겨있는지, feature는 무엇이고 label은 무엇인지 확인해 보면서 진행하는 점, 잊지마세요!\n",
    "\n",
    "**(1) 필요한 모듈 import하기**\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "**(2) 데이터 준비**\n",
    "\n",
    "load_wine 메서드를 사용합니다.\n",
    "\n",
    "**(3) 데이터 이해하기**\n",
    "\n",
    "지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
    "\n",
    "Feature Data 지정하기\n",
    "Label Data 지정하기\n",
    "Target Names 출력해 보기\n",
    "데이터 Describe 해 보기\n",
    "\n",
    "**(4) train, test 데이터 분리**\n",
    "\n",
    "모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
    "X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n",
    "\n",
    "**(5) 다양한 모델로 학습시켜보기**\n",
    "\n",
    "학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
    "\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기\n",
    "\n",
    "**(6) 모델을 평가해 보기**\n",
    "\n",
    "학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-killer",
   "metadata": {},
   "source": [
    "### 1. Decision Tree 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "continent-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# (2) 데이터 준비\n",
    "data = load_wine()\n",
    "data_data = data.data\n",
    "data_label = data.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-bookmark",
   "metadata": {},
   "source": [
    "### 2. Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "spanish-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "randomforest_tree = RandomForestClassifier(random_state=32)\n",
    "randomforest_tree.fit(X_train, y_train)\n",
    "y_pred = randomforest_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-macro",
   "metadata": {},
   "source": [
    "### 3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "requested-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-slope",
   "metadata": {},
   "source": [
    "### 4. SGD Classifier 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ahead-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54         7\n",
      "           1       0.91      0.59      0.71        17\n",
      "           2       0.67      0.33      0.44        12\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.65      0.64      0.57        36\n",
      "weighted avg       0.72      0.58      0.59        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-threshold",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "developing-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(random_state=32, max_iter = 5000, solver='lbfgs')\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-candy",
   "metadata": {},
   "source": [
    "## 2-13. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다\n",
    "\n",
    "마지막으로 유방암 여부를 진단해 보겠습니다.\n",
    "이 데이터 또한 여러 사람의 건강 지표에 대한 데이터가 feature로 들어가있고, 유방암의 여부가 True, False로 label이 됩니다.\n",
    "\n",
    "주어진 데이터로 환자의 유방암 여부를 분류해 볼 수 있을까요?\n",
    "\n",
    "**(1) 필요한 모듈 import하기**\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "**(2) 데이터 준비**\n",
    "\n",
    "load_breast_cancer 메서드를 사용합니다.\n",
    "\n",
    "**(3) 데이터 이해하기**\n",
    "\n",
    "지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
    "\n",
    "Feature Data 지정하기\n",
    "Label Data 지정하기\n",
    "Target Names 출력해 보기\n",
    "데이터 Describe 해 보기\n",
    "\n",
    "**(4) train, test 데이터 분리**\n",
    "\n",
    "모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
    "X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n",
    "\n",
    "**(5) 다양한 모델로 학습시켜보기**\n",
    "\n",
    "학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
    "\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기\n",
    "\n",
    "**(6) 모델을 평가해 보기**\n",
    "\n",
    "학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n",
    "\n",
    "**마무리**\n",
    "\n",
    "모든 실습을 따라오시느라 정말 수고하셨습니다 👏🏼👏🏼👏🏼\n",
    "\n",
    "오늘 우리는 어떤 것을 배웠나요?\n",
    "\n",
    "- **Iris의 세 가지 품종, 분류해 볼까요?** 에서는 scikit-learn의 예제 데이터와 붓꽃 데이터에 대해 알아보았습니다.\n",
    "- **첫 번째 머신러닝 실습, 간단하고도 빠르게!** 에서는 붓꽃 데이터와 다양한 분류 모델을 이용해 빠른 실습을 진행해봤죠.\n",
    "- **내 모델은 얼마나 똑똑한가? 다양하게 평가해 보기** 에서는 모델의 성능을 평가하는 다양한 지표에 대해 알아보았습니다.\n",
    "- 마지막 **프로젝트** 에서는 직접 다른 데이터들로 실습을 진행해 보았습니다.\n",
    "\n",
    "어떤가요?\n",
    "오늘 실습으로 분류에 대한 대략적인 개요와 scikit-learn의 모델 학습 API 형태를 잘 익혀본 것 같습니다.\n",
    "물론 오늘 다 다루지 못한 분류 알고리즘에 대한 이론이나, 모델의 성능을 보다 높이기 위한 기술적인 부분들은 앞으로 훨씬 많이 배워야 하겠지만요!\n",
    "\n",
    "앞으로의 과정이 더욱 기대되지 않나요?! 그 전까지 오늘 배운 것들은 꼭 복습하기로 하고, 우리는 다음 시간에 또 만나요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-trademark",
   "metadata": {},
   "source": [
    "### 1. Decision Tree 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "labeled-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# (2) 데이터 준비\n",
    "data = load_breast_cancer()\n",
    "data_data = data.data\n",
    "data_label = data.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_data, \n",
    "                                                    data_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-accused",
   "metadata": {},
   "source": [
    "### 2. Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "solar-english",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "randomforest_tree = RandomForestClassifier(random_state=32)\n",
    "randomforest_tree.fit(X_train, y_train)\n",
    "y_pred = randomforest_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-green",
   "metadata": {},
   "source": [
    "### 3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "favorite-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-joseph",
   "metadata": {},
   "source": [
    "### 4. SGD Classifier 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "roman-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        40\n",
      "           1       0.92      0.91      0.91        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.87      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-vintage",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "favorite-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(random_state=32, max_iter = 5000, solver='lbfgs')\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-triple",
   "metadata": {},
   "source": [
    "평가문항|상세기준\n",
    "---|---\n",
    "1. 3가지 데이터셋의 구성이 합리적으로 진행되었는가?|feature와 label 선정을 위한 데이터 분석과정이 체계적으로 전개됨\n",
    "2. 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?|모델학습 및 테스트가 정상적으로 수행되었음\n",
    "3. 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가?|평가지표 선택 및 이유 설명이 타당함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
